{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deterministic Case \n",
    "In this case, the input is deterministic, and regardless of the shape of the tensor the result of the calculation is the same. With an input vector of y_pred and y_gt, it would return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9888486133306684"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate fake data\n",
    "y_gt = np.random.randn(100,4,2)\n",
    "y_pred = np.random.randn(100,4,2)\n",
    "#calculate it \n",
    "np.sum( np.square(y_gt-y_pred)) # if reduction is sum\n",
    "np.mean(np.square(y_gt-y_pred)) # if reduction is mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bivariate Case\n",
    "If the input is bivariate, and the input prediction contains the values in the form \n",
    "$$  [ \\mu_x, \\mu_y, \\rho, var_x, var_y ] $$\n",
    "Then one would calculate the distance using the mahalobis distance in the following method:\n",
    "1. First reshape the inputs to have the same number of rows (np.reshape was verified to be consistent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypb = np.random.rand(100,3,7,5) #generate y input\n",
    "y_gt = np.random.rand(100,3,7,2) #generate ground truth\n",
    "y_means = ypb.reshape(-1,5) #Reshape it into 2d\n",
    "y_dat = y_gt.reshape(-1,2) #reshape it into 2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Form the vector for the difference between the mean for the mahalanobis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.stack( (y_dat[:,0] - y_means[:,0], y_dat[:,1] - y_means[:,1]) ,axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.44987614, -0.47171335],\n",
       "       [-0.11302183, -0.05141372],\n",
       "       [-0.63571928,  0.44535003],\n",
       "       ...,\n",
       "       [-0.05787041,  0.48233983],\n",
       "       [-0.20424652,  0.57753605],\n",
       "       [-0.23454623, -0.4488786 ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. For each mean difference, calculate the Mahalanobis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3662.4663635136026"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "cv = np.zeros((2,2))\n",
    "cov = np.zeros((2,2))  #Einsum \n",
    "for i in range(len(means)):\n",
    "    v = means[i]\n",
    "    cov[0,0] = y_means[i,3]\n",
    "    cov[1,1] = y_means[i,4]\n",
    "    cov[0,1] = cov[1,0] = np.sqrt(y_means[i,3]*y_means[i,4])*y_means[i,2]\n",
    "    cv = np.concatenate((cv,cov))\n",
    "    total+= sqrt((v.T @ np.linalg.inv(cov) @ v))\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3662.4663635136094\n"
     ]
    }
   ],
   "source": [
    "cv = np.zeros((2,2))\n",
    "cov = np.zeros((2,2))  #Einsum \n",
    "for i in range(len(means)):\n",
    "    cov[0,0] = y_means[i,3]\n",
    "    cov[1,1] = y_means[i,4]\n",
    "    cov[0,1] = cov[1,0] = np.sqrt(y_means[i,3]*y_means[i,4])*y_means[i,2]\n",
    "    cov = np.linalg.inv(cov)\n",
    "    cv = np.concatenate((cv,cov))\n",
    "cv = cv[2:] # all covariances\n",
    "lv = np.repeat(means, repeats=2, axis = 0) #contains means duplicated\n",
    "t = lv*cv\n",
    "t = t.sum(axis=1)\n",
    "t = means.flatten()* t\n",
    "t = t[1::2] + t[::2] # take evens only, odds only, and sum corresponding ones\n",
    "t = np.sqrt(t)\n",
    "print(t.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate case\n",
    "This assumes a 5d tensor where the last two dimensions are in the form (samples, coordinates). For example, an input could be (200,100,5,100,2) where it is the batch, pedestrian, future step, samples, and coordinates of the samples. It will iterate through every group of samples, fit a gmm to it, and calculate a multivariate mahalanobis distance to the overall cluster center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02054451 0.00406262]\n",
      " [0.00406262 0.07809063]]\n",
      "tied\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'true_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2730204e17f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mcenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmahalanobis_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariances_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#assume it will be the true value, add parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m#find the mahalanobis distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'true_value' is not defined"
     ]
    }
   ],
   "source": [
    "total=0\n",
    "samples = np.random.rand(200, 100,5,100, 2)\n",
    "for i in samples:\n",
    "    for pedestrian in i:\n",
    "        for steps in pedestrian:\n",
    "           #do the method of finding the best bic\n",
    "            gmm = get_best_gmm(steps)\n",
    "            center = np.sum(np.multiply(gmm.means_, gmm.weights_[:,np.newaxis]), axis = 0)\n",
    "            dist = mahalanobis_d(center, true_value, len(gmm.weights_),gmm.covariances_, gmm.means_,gmm.weights_) #assume it will be the true value, add parameters\n",
    "            total = total+dist\n",
    "            #find the mahalanobis distance\n",
    "            #For now compare the true mean to center of all the clusters\n",
    "            \n",
    "#total is reduction sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The helper method to find the mahalanobis distance is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahalanobis_d(x,y,n_clusters, ccov, cmeans,cluster_p): #ccov \n",
    "    v = np.array(x-y)\n",
    "    Gnum = 0\n",
    "    Gden = 0\n",
    "    for i in range(0,n_clusters):\n",
    "        ck = np.linalg.inv(ccov[i])\n",
    "        u = np.array(cmeans[i] - y)\n",
    "        val = ck*cluster_p[i]\n",
    "        b2 =  1/(v.T @ ck @v)\n",
    "        a = b2 * v.T @ ck @ u\n",
    "        Z = u.T @ ck @ u - b2 * (v.T @ ck @ u)**2\n",
    "        pxk = sqrt(np.pi*b2/2)*exp(-Z/2) * (erf((1-a)/sqrt(2*b2)) - erf(-a/sqrt(2*b2)))\n",
    "        Gnum+= val*pxk \n",
    "        Gden += cluster_p[i] * pxk\n",
    "\n",
    "    G = Gnum/Gden\n",
    "    mdist = sqrt(v.T @ G @ v)\n",
    "    print( \"Mahalanobis distance between \" + str(x) + \" and \"+str(y) + \" is \"+ str(mdist) )\n",
    "    return mdist "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method to find the best gmm uses BIC, and is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_gmm(X):\n",
    "    lowest_bic = np.infty\n",
    "    bic = []\n",
    "    n_components_range = range(1, 7)  ## stop based on fit/small BIC change/ earlystopping\n",
    "    cv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "    best_gmm = GaussianMixture()\n",
    "    for cv_type in cv_types:\n",
    "        for n_components in n_components_range:\n",
    "            # Fit a Gaussian mixture with EM\n",
    "            gmm = GaussianMixture(n_components=n_components,\n",
    "                                          covariance_type=cv_type)\n",
    "            gmm.fit(X)\n",
    "            bic.append(gmm.bic(X))\n",
    "            if bic[-1] < lowest_bic :\n",
    "                lowest_bic = bic[-1]\n",
    "                best_gmm = gmm\n",
    "\n",
    "    bic = np.array(bic)\n",
    "    return best_gmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping GMM search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopping version\n",
    "def get_best_gmm2(X):\n",
    "    lowest_bic = np.nfty\n",
    "    bic = []\n",
    "    n_components_range = range(1, 7)  ## stop based on fit/small BIC change/ earlystopping\n",
    "    cv_types = ['full'] #changed to only looking for full covariance \n",
    "    best_gmm = GaussianMixture()\n",
    "    for cv_type in cv_types:\n",
    "        p=10    #Decide a value \n",
    "        n_comps = 1\n",
    "        j = 0\n",
    "        while j < p # if hasn't improved in p times, then stop. Do it for each cv type and take the minimum of all of them\n",
    "            gmm = GaussianMixture(n_components=n_comps, covariance_type=cv_type)\n",
    "            gmm.fit(X)\n",
    "            bic.append(gmm.bic(X))\n",
    "            if bic[-1] < lowest_bic:\n",
    "                lowest_bic = bic[-1]\n",
    "                best_gmm = gmm\n",
    "                j = 0   #reset counter\n",
    "            else: #increment counter\n",
    "                j+=1\n",
    "\n",
    "    bic = np.array(bic)\n",
    "    return best_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
